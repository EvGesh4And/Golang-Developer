# Паттерны конкурентности в Go: Пайплайны и отмена
Автор: Sameer Ajmani
13 марта 2014 года

## Введение

Примитивы конкурентности в Go позволяют легко создавать конвейеры потоковой обработки данных, эффективно использующие ввод-вывод и многоядерные процессоры. В этой статье представлены примеры таких конвейеров, разобраны тонкости, возникающие при ошибках, и показаны техники для их корректной обработки.

## Что такое пайплайн (pipeline)?

В Go нет формального определения пайплайна; это просто один из видов конкурентных программ. Неофициально, **пайплайн** — это серия этапов, соединенных каналами, где каждый этап представляет собой группу горутин, выполняющих одну и ту же функцию. На каждом этапе горутины:

- получают значения из *восходящего потока* по *входящим* каналам;
- выполняют какую-то операцию с этими данными, обычно создавая новые значения;
- отправляют значения *вниз по потоку* по *исходящим* каналам.

Каждый этап может иметь любое количество входных и выходных каналов, за исключением первого и последнего этапов, которые имеют только выходные или входные каналы, соответственно. Первый этап иногда называют `источником (source)` или `производителем (producer)`, последний — `приемником (sink)` или `потребителем (consumer)`.

Мы начнем с простого примера пайплайна, чтобы объяснить идеи и методы. Позже мы представим более реалистичный пример.

## Возведение чисел в квадрат
Рассмотрим пайплайн из трёх этапов.

**Первый этап** — функция `gen`, которая преобразует список целых чисел в канал, передающий эти числа. Функция `gen` запускает горутину, отправляющую числа в канал и закрывающую его после отправки всех значений:

```go
func gen(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}
```

**Второй этап** — функция `sq`, которая принимает целые числа из канала и возвращает канал, передающий квадраты полученных чисел. После закрытия входящего канала и отправки всех значений дальше, этап закрывает исходящий канал:

```go
func sq(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}
```

Функция `main` настраивает пайплайн и запускает финальный этап: получает значения из второго этапа и выводит их, пока канал не закроется:

```go
func main() {
    // Настраиваем конвейер.
    c := gen(2, 3)
    out := sq(c)

    // Получаем и выводим результаты.
    fmt.Println(<-out) // 4
    fmt.Println(<-out) // 9
}
```

Поскольку у `sq` одинаковые типы входящего и исходящего каналов, её можно комбинировать любое количество раз. Можно также переписать `main` с использованием цикла `range`, как в других этапах:

```go
func main() {
    // Настраиваем конвейер и выводим результаты.
    for n := range sq(sq(gen(2, 3))) {
        fmt.Println(n) // Сначала 16, затем 81
    }
}
```

## Fan-out, fan-in

*Fan-out* — это когда несколько функций читают из одного канала, пока он не закроется. Это позволяет распределять задачи между несколькими обработчиками, параллельно используя CPU и I/O.

*Fan-in* — это когда функция читает из нескольких входных каналов и продолжает работу, пока все они не закроются, объединяя их в один выходной канал, который закрывается после закрытия всех входов.

Модифицируем наш конвейер, запустив два экземпляра `sq`, каждый из которых читает из одного и того же входного канала. Добавим новую функцию `merge` для объединения результатов (*fan-in*):

```go
func main() {
    in := gen(2, 3)

    // Распределим работу между двумя горутинами, которые читают из `in`.
    c1 := sq(in)
    c2 := sq(in)

    // Читаем объединённый результат из `c1` и `c2`.
    for n := range merge(c1, c2) {
        fmt.Println(n) // 4, затем 9, или 9, затем 4
    }
}
```

Функция `merge` преобразует список каналов в один, запуская горутину для каждого входящего канала, которая копирует значения в результирующий канал. После запуска всех горутин `merge` запускает ещё одну, чтобы закрыть выходной канал после завершения всех отправок.

Отправка в закрытый канал вызывает **panic**, поэтому важно убедиться, что все отправки завершены до вызова `close`. Для синхронизации можно использовать `sync.WaitGroup`:

```go
func merge(cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Запускаем горутину для каждого входного канала.
    output := func(c <-chan int) {
        for n := range c {
            out <- n
        }
        wg.Done()
    }
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }

    // Запускаем горутину, которая закроет out, когда все горутины завершатся.
    go func() {
        wg.Wait()
        close(out)
    }()
    return out
}
```

## Досрочная остановка (Stopping short)

Существует общий паттерн работы функций в пайплайне:

1. Каждый этап закрывает свой выходной канал, когда все отправки завершены.
2. Каждый этап получает данные из входного канала, пока тот не закроется.

Это позволяет использовать `range` для обработки данных и гарантирует, что горутины завершатся, когда все данные успешно переданы дальше.

Однако в реальных пайплайнах некоторые этапы могут **не обрабатывать все входные данные** (не всегда получают все входные значения). Причины могут быть разными:

- Получателю требуется только часть данных.
- Полученное значение сигнализирует об ошибке, и дальнейшая обработка прекращается.

В любом случае получатель не должен ждать оставшиеся значения, а предыдущие этапы должны прекратить генерацию ненужных значений.

Если этап **не считывает все входные данные**, горутины на предыдущих этапах могут зависнуть в ожидании возможности отправки данных. Например:

```go
// Читаем только одно значение.
out := merge(c1, c2)
fmt.Println(<-out) // 4 или 9
return
// Вторая горутина зависнет, пытаясь отправить второе значение.
```

Это **утечка ресурсов**: зависшие горутины продолжают занимать память и процессорное время, а их стеки могут удерживать ссылки на данные, не позволяя сборщику мусора освободить их. **Горутины не очищаются автоматически**, они должны завершаться самостоятельно.

Нам необходимо обеспечить выход вышестоящих этапов конвейера даже в случаях, когда нижестоящие этапы не получают все входящие значения.

### Решение с буферизацией

Один из способов достичь этого — **сделать исходящие каналы буферизированными**. Буфер может содержать фиксированное количество значений; операции отправки завершаются немедленно, если в буфере есть место:о:

```go
c := make(chan int, 2) // размер буфера 2  
c <- 1  // выполняется немедленно  
c <- 2  // выполняется немедленно  
c <- 3  // блокируется, пока другая горутина не выполнит <-c и не получит 1  
```

Когда количество отправляемых значений известно в момент создания канала, буферизация может упростить код. Например, мы можем переписать функцию `gen`, чтобы она копировала список целых чисел в буферизированный канал, избегая создания новой горутины:

```go
func gen(nums ...int) <-chan int {  
    out := make(chan int, len(nums))  
    for _, n := range nums {  
        out <- n  
    }  
    close(out)  
    return out  
}  
```

Возвращаясь к проблеме заблокированных горутин в нашем конвейере, мы могли бы добавить буфер к исходящему каналу, возвращаемому функцией `merge`:

```go
func merge(cs ...<-chan int) <-chan int {  
    var wg sync.WaitGroup  
    out := make(chan int, 1) // достаточно места для непрочитанных входных данных  
    // ... остальной код остается без изменений ...  
}  
```

Хотя это исправляет проблему заблокированных горутин в данной программе, такой код является плохим. Выбор размера буфера равного 1 здесь зависит от знания количества значений, которые получит `merge`, и количества значений, которые будут потреблены нижестоящими этапами. Это ненадежно: если мы передадим дополнительное значение в `gen`, или если нижестоящий этап прочитает меньше значений, у нас снова появятся заблокированные горутины.

Вместо этого нам необходимо предоставить способ, позволяющий нижестоящим этапам указывать отправителям, что они прекращают прием входных данных.

### Явная отмена

Когда функция `main` решает завершить работу, не получив все значения из канала `out`, она должна уведомить горутины в вышестоящих этапах о необходимости прекратить отправку значений. Это осуществляется путем отправки сигналов через канал `done`. В данном случае отправляется два значения, так как потенциально могут быть два заблокированных отправителя:

```go
func main() {
    in := gen(2, 3)

    // Распределяем обработку sq между двумя горутинами
    c1 := sq(in)
    c2 := sq(in)

    // Получаем первое значение из выходного канала
    done := make(chan struct{}, 2)
    out := merge(done, c1, c2)
    fmt.Println(<-out) // 4 или 9

    // Уведомляем оставшихся отправителей о завершении
    done <- struct{}{}
    done <- struct{}{}
}
```

Отправляющие горутины заменяют свою операцию отправки оператором `select`, который выполняется либо при успешной отправке в `out`, либо при получении значения из `done`. Тип значения `done` — пустая структура, так как само значение не имеет значения: важно только событие приема, которое указывает, что отправку в `out` следует прекратить. Горутины продолжат обрабатывать входящие данные из `c`, так что вышестоящие этапы не будут заблокированы. (Чуть позже мы обсудим, как завершать этот цикл досрочно.)

```go
func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Запускаем горутину вывода для каждого входного канала в cs.
    // output копирует значения из c в out, пока c не будет закрыт
    // или пока не получит значение из done, затем вызывает wg.Done.
    output := func(c <-chan int) {
        for n := range c {
            select {
            case out <- n:
            case <-done:
            }
        }
        wg.Done()
    }
    // ... остальной код остается без изменений ...
}
```
У такого подхода есть проблемы:

- **Жесткая привязка** к количеству отправителей: Каждый получатель должен знать точное количество потенциально заблокированных отправителей
- **Сложность сопровождения**: Подсчет количества необходимых сигналов подвержен ошибкам
- **Негибкость**: Не подходит для неизвестного или неограниченного числа горутин

### Решение через закрытие канала

Нам нужен способ сообщить неопределенному и неограниченному количеству горутин прекратить отправку значений вниз по потоку. В Go это можно сделать путем закрытия канала, так как [операция чтения из закрытого канала всегда выполняется немедленно, возвращая нулевое значение типа элемента](https://go.dev/ref/spec#Receive_operator).

Это означает, что `main` может разблокировать всех отправителей просто закрыв канал `done`. Закрытие канала фактически становится широковещательным сигналом для всех отправителей. Мы расширяем каждую из наших функций пайлайна, чтобы они принимали `done` в качестве параметра, и используем `defer close(done)`, чтобы гарантировать, что при любом выходе из `main` все этапы конвейера получат сигнал завершения.

```go
func main() {
    // Создаем канал done, который будет общим для всего конвейера,
    // и закрываем этот канал при выходе из конвейера, подавая сигнал
    // всем запущенным горутинам о завершении работы.
    done := make(chan struct{})
    defer close(done)          

    in := gen(done, 2, 3)

    // Распределяем вычисления sq между двумя горутинами, которые читают из in.
    c1 := sq(done, in)
    c2 := sq(done, in)

    // Читаем первое значение из выхода.
    out := merge(done, c1, c2)
    fmt.Println(<-out) // 4 или 9

    // done будет закрыт через отложенный вызов defer.
}
```

Теперь каждый этап нашего конвейера может завершаться сразу после закрытия `done`. Выходная горутина в `merge` может завершиться, не извлекая все значения из своего входного канала, так как она знает, что вышестоящий отправитель (`sq`) прекратит попытки отправки, когда `done` будет закрыт. Горутина `output` гарантирует вызов `wg.Done` на всех путях выхода через `defer`:

```go
func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Запускаем горутину вывода для каждого входного канала в cs.
    // output копирует значения из c в out, пока c или done не будут закрыты,
    // затем вызывает wg.Done.
    output := func(c <-chan int) {
        defer wg.Done()
        for n := range c {
            select {
            case out <- n:
            case <-done:
                return
            }
        }
    }
    // ... остальной код остается без изменений ...
}
```

Аналогично, `sq` может завершаться сразу после закрытия `done`. `sq` гарантирует, что его выходной канал закрывается на всех путях выхода через `defer`:

```go
func sq(done <-chan struct{}, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            select {
            case out <- n * n:
            case <-done:
                return
            }
        }
    }()
    return out
}
```

**Основные принципы построения конвейеров**:

- Этапы закрывают свои выходные каналы, когда все операции отправки завершены.
- Этапы продолжают получать значения из входных каналов, пока эти каналы не будут закрыты или пока отправители не будут разблокированы.

Конвейеры разблокируют отправителей либо обеспечивая достаточный буфер для всех отправленных значений, либо явно сигнализируя отправителям, когда получатель может отказаться от канала.

## Разбор дерева

Рассмотрим более реалистичный конвейер.

MD5 — это алгоритм хеширования сообщений, полезный в качестве контрольной суммы файла. Утилита командной строки md5sum выводит хеш-значения для списка файлов.

```go
% md5sum *.go
d47c2bbc28298ca9befdfbc5d3aa4e65  bounded.go
ee869afd31f83cbb2d10ee81b2b831dc  parallel.go
b88175e65fdcbc01ac08aaf1fd9b5e96  serial.go
```

Наш пример программы работает аналогично md5sum, но принимает в качестве аргумента одну директорию и выводит хеш-значения для каждого обычного файла в этой директории, отсортированные по имени пути.

```go
% go run serial.go .
d47c2bbc28298ca9befdfbc5d3aa4e65  bounded.go
ee869afd31f83cbb2d10ee81b2b831dc  parallel.go
b88175e65fdcbc01ac08aaf1fd9b5e96  serial.go
```

Основная функция нашей программы вызывает вспомогательную функцию `MD5All`, которая возвращает отображение (map) из имени файла в его хеш-значение, затем сортирует и выводит результаты:

```go
func main() {
    // Вычисляем хеш MD5 для всех файлов в указанной директории,
    // затем выводим результаты, отсортированные по имени пути.
    m, err := MD5All(os.Args[1])
    if err != nil {
        fmt.Println(err)
        return
    }
    var paths []string
    for path := range m {
        paths = append(paths, path)
    }
    sort.Strings(paths)
    for _, path := range paths {
        fmt.Printf("%x  %s\n", m[path], path)
    }
}
```

Функция `MD5All` является ключевым моментом в нашем обсуждении. В `serial.go` реализация не использует конкурентность и просто читает и вычисляет хеш каждого файла при обходе дерева.

```go
// MD5All читает все файлы в дереве каталогов с корнем в `root`
// и возвращает отображение из пути файла в его MD5-хеш.
// Если обход каталога или чтение файла завершается с ошибкой, MD5All возвращает ошибку.
func MD5All(root string) (map[string][md5.Size]byte, error) {
    m := make(map[string][md5.Size]byte)
    err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        if !info.Mode().IsRegular() {
            return nil
        }
        data, err := ioutil.ReadFile(path)
        if err != nil {
            return err
        }
        m[path] = md5.Sum(data)
        return nil
    })
    if err != nil {
        return nil, err
    }
    return m, nil
}
```

### Параллельное вычисление хеша

В `parallel.go` мы разбиваем `MD5All` на двухэтапный конвейер. На первом этапе `sumFiles` выполняет обход дерева, вычисляет хеш каждого файла в новой горутине и отправляет результаты в канал с типом `result`:


```go
type result struct {
    path string
    sum  [md5.Size]byte
    err  error
}
```

В этой реализации `sumFiles` возвращает два канала:

- один для результатов (`c`),
- другой для ошибки, полученной от `filepath.Walk` (`errc`).

Функция `filepath.Walk` запускает новую горутину для обработки каждого обычного файла, затем проверяет `done`. Если done закрыт, обход (walk) немедленно останавливается.

```go
func sumFiles(done <-chan struct{}, root string) (<-chan result, <-chan error) {
    // Для каждого обычного файла запускается горутина, которая вычисляет хеш и отправляет результат в канал c.
    // Результат работы Walk передаётся в errc.
    c := make(chan result)
    errc := make(chan error, 1)

    go func() {
        var wg sync.WaitGroup
        err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
            if err != nil {
                return err
            }
            if !info.Mode().IsRegular() {
                return nil
            }
            wg.Add(1)
            go func() {
                data, err := ioutil.ReadFile(path)
                select {
                case c <- result{path, md5.Sum(data), err}: // Отправка результата
                case <-done: // Если канал закрыт, прерываемся
                }
                wg.Done()
            }()
            // Проверка закрытия done: если закрыт, выходим
            select {
            case <-done:
                return errors.New("walk canceled")
            default:
                return nil
            }
        })

        // После завершения Walk, когда все вызовы wg.Add выполнены,
        // стартует горутина для закрытия канала c после завершения всех горутин
        go func() {
            wg.Wait()
            close(c)
        }()

        // errc имеет буфер, поэтому select не нужен
        errc <- err
    }()
    return c, errc
}
```

MD5All получает значения хешей из канала `c`. В случае ошибки `MD5All` завершает работу досрочно, закрывая канал `done` с помощью `defer`:

```go
func MD5All(root string) (map[string][md5.Size]byte, error) {
    // MD5All закрывает канал done при выходе; это может произойти раньше,
    // чем будут получены все значения из c и errc.
    done := make(chan struct{})
    defer close(done)          

    c, errc := sumFiles(done, root)

    m := make(map[string][md5.Size]byte)
    for r := range c {
        if r.err != nil {
            return nil, r.err
        }
        m[r.path] = r.sum
    }
    if err := <-errc; err != nil {
        return nil, err
    }
    return m, nil
}
```

## Ограниченный уровень параллелизма

Реализация `MD5All` в [`parallel.go`](https://go.dev/blog/pipelines/parallel.go) запускает новую горутину для каждого файла. В каталоге с большим количеством крупных файлов это может привести к чрезмерному выделению памяти.

Мы можем ограничить такие выделения, задав фиксированное количество горутин для чтения файлов. В [`bounded.go`](https://go.dev/blog/pipelines/bounded.go) мы создаем три этапа в конвейере: обход дерева, чтение и хеширование файлов, а затем сбор результатов.

**Первый этап: обход файловой системы**

Функция `walkFiles` передает пути обычных файлов в дереве:

```go
func walkFiles(done <-chan struct{}, root string) (<-chan string, <-chan error) {
    paths := make(chan string)
    errc := make(chan error, 1)
    go func() {
        // Закрываем канал paths после завершения Walk.
        defer close(paths)
        // Здесь select не нужен, так как errc буферизирован.
        errc <- filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
            if err != nil {
                return err
            }
            if !info.Mode().IsRegular() {
                return nil
            }
            select {
            case paths <- path:
            case <-done:
                return errors.New("walk canceled")
            }
            return nil
        })
    }()
    return paths, errc
}
```

**Второй этап: запуск фиксированного количества горутин для вычисления хешей**

func digester(done <-chan struct{}, paths <-chan string, c chan<- result) {
    for path := range paths {
        data, err := ioutil.ReadFile(path)
        select {
        case c <- result{path, md5.Sum(data), err}:
        case <-done:
            return
        }
    }
}
В отличие от предыдущих примеров, `digester` не закрывает канал `c`, так как в него отправляют данные несколько горутин. Вместо этого `MD5All` следит за тем, чтобы канал закрывался, когда все горутины завершат работу:

```go
// Запускаем фиксированное количество горутин для вычисления хешей.
c := make(chan result)
var wg sync.WaitGroup
const numDigesters = 20
wg.Add(numDigesters)
for i := 0; i < numDigesters; i++ {
    go func() {
        digester(done, paths, c)
        wg.Done()
    }()
}
go func() {
    wg.Wait()
    close(c)
}()
```

Если бы каждая `digester`-горутина создавала и возвращала свой собственный канал, нам бы пришлось использовать дополнительные горутины для объединения результатов.

**Финальный этап: сбор результатов**

Финальный этап получает все результаты из `c`, а затем проверяет ошибки из `errc`. Проверку ошибки нельзя выполнить раньше, так как до этого момента `walkFiles` мог быть заблокирован при отправке значений:

```go
m := make(map[string][md5.Size]byte)
for r := range c {
    if r.err != nil {
        return nil, r.err
    }
    m[r.path] = r.sum
}
// Проверяем, не произошла ли ошибка Walk.
if err := <-errc; err != nil {
    return nil, err
}
return m, nil
```

## Заключение

В этой статье представлены техники построения потоковых конвейеров данных в Go. Обработка ошибок в таких конвейерах сложна, так как каждый этап может блокироваться, пытаясь отправить данные вниз по потоку, а нижестоящие этапы могут уже не интересоваться входящими данными. Мы показали, как закрытие канала может служить сигналом «done» для всех горутин конвейера, а также предложили рекомендации по правильному построению конвейеров.

Дополнительные материалы:

- [Go Concurrency Patterns](https://go.dev/talks/2012/concurrency.slide#1) ([видео](https://www.youtube.com/watch?v=f6kdp27TYZs)) — основные примитивы конкурентности в Go и способы их применения.
- [Advanced Go Concurrency Patterns](https://go.dev/blog/io2013-talk-concurrency) ([видео](https://www.youtube.com/watch?v=QDDwwePbDtw)) — сложные примеры использования примитивов Go, особенно `select`.
- [Squinting at Power Series](https://swtch.com/~rsc/thread/squint.pdf) — статья Дугласа МакИлроя о том, как потоковая обработка данных (аналогичная реализованной в Go) позволяет элегантно решать сложные задачи.